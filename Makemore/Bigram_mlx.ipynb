{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Train a simple MLP on MNIST with MLX. [-h] [--gpu]\n",
      "                                             [--dataset {mnist,fashion_mnist}]\n",
      "Train a simple MLP on MNIST with MLX.: error: unrecognized arguments: --f=/Users/viranchee/Library/Jupyter/runtime/kernel-v2-27908jSGvyHMcs0PH.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/code/envs/mlx/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright Â© 2023 Apple Inc.\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np\n",
    "\n",
    "import mnist\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"A simple MLP.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_layers: int, input_dim: int, hidden_dim: int, output_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layer_sizes = [input_dim] + [hidden_dim] * num_layers + [output_dim]\n",
    "        self.layers = [\n",
    "            nn.Linear(idim, odim)\n",
    "            for idim, odim in zip(layer_sizes[:-1], layer_sizes[1:])\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers[:-1]:\n",
    "            x = nn.relu(l(x))\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "\n",
    "def loss_fn(model, X, y):\n",
    "    return nn.losses.cross_entropy(model(X), y, reduction=\"mean\")\n",
    "\n",
    "\n",
    "def batch_iterate(batch_size, X, y):\n",
    "    perm = mx.array(np.random.permutation(y.size))\n",
    "    for s in range(0, y.size, batch_size):\n",
    "        ids = perm[s : s + batch_size]\n",
    "        yield X[ids], y[ids]\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    seed = 0\n",
    "    num_layers = 2\n",
    "    hidden_dim = 32\n",
    "    num_classes = 10\n",
    "    batch_size = 256\n",
    "    num_epochs = 10\n",
    "    learning_rate = 1e-1\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Load the data\n",
    "    train_images, train_labels, test_images, test_labels = map(\n",
    "        mx.array, getattr(mnist, args.dataset)()\n",
    "    )\n",
    "\n",
    "    # Load the model\n",
    "    model = MLP(num_layers, train_images.shape[-1], hidden_dim, num_classes)\n",
    "    mx.eval(model.parameters())\n",
    "\n",
    "    optimizer = optim.SGD(learning_rate=learning_rate)\n",
    "    loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "    @partial(mx.compile, inputs=model.state, outputs=model.state)\n",
    "    def step(X, y):\n",
    "        loss, grads = loss_and_grad_fn(model, X, y)\n",
    "        optimizer.update(model, grads)\n",
    "        return loss\n",
    "\n",
    "    @partial(mx.compile, inputs=model.state)\n",
    "    def eval_fn(X, y):\n",
    "        return mx.mean(mx.argmax(model(X), axis=1) == y)\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        tic = time.perf_counter()\n",
    "        for X, y in batch_iterate(batch_size, train_images, train_labels):\n",
    "            step(X, y)\n",
    "            mx.eval(model.state)\n",
    "        accuracy = eval_fn(test_images, test_labels)\n",
    "        toc = time.perf_counter()\n",
    "        print(\n",
    "            f\"Epoch {e}: Test accuracy {accuracy.item():.3f},\"\n",
    "            f\" Time {toc - tic:.3f} (s)\"\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\"Train a simple MLP on MNIST with MLX.\")\n",
    "    parser.add_argument(\"--gpu\", action=\"store_true\", help=\"Use the Metal back-end.\")\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        type=str,\n",
    "        default=\"mnist\",\n",
    "        choices=[\"mnist\", \"fashion_mnist\"],\n",
    "        help=\"The dataset to use.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    if not args.gpu:\n",
    "        mx.set_default_device(mx.cpu)\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
