{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1356048"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1058130d0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/code/envs/mlx/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9798219, 3), mlx.core.int32, (9798219,), mlx.core.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "blocksize = 3 # Context length for prediction\n",
    "X, Y = [], [] # X: Input, Y: Label to the neural net\n",
    "\n",
    "for w in words:\n",
    "  # print(w)\n",
    "  context = [0] * blocksize\n",
    "  for ch in w + '.':\n",
    "    ix = stoi[ch] # Prediction\n",
    "    X.append(context)\n",
    "    Y.append(ix)\n",
    "    # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "    context = context[1:] + [ix]\n",
    "\n",
    "X = mx.array(X)\n",
    "Y = mx.array(Y)\n",
    "\n",
    "# X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 5],\n",
       "       [0, 5, 13],\n",
       "       ...,\n",
       "       [9, 17, 21],\n",
       "       [17, 21, 1],\n",
       "       [21, 1, 14]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "  nInputLayer: int = 1\n",
    "  nHiddenLayers: list[int] = None\n",
    "  nOutputLayer: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "  def __init__(self, config: ModelConfig):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Linear(config.nInputLayer, config.nOutputLayer, bias=False)\n",
    "  \n",
    "  def __call__(self, ix):\n",
    "    logits = self.layers[ix] * ix\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(axis=1, keepdims=True)\n",
    "    loss = - probs[ix].mean().log()\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConfig(nInputLayer=27, nOutputLayer=27)\n",
    "bigram = BigramModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x, y):\n",
    "  y_hat = bigram(x)\n",
    "  print(type(y_hat))\n",
    "  return (y_hat - y).square().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 27)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params= bigram.parameters()\n",
    "layers = params[\"layers\"]\n",
    "layers\n",
    "weight = layers[\"weight\"]\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossNgrad = nn.value_and_grad(bigram, loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlossNgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/code/envs/mlx/lib/python3.11/site-packages/mlx/nn/utils.py:34\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.wrapped_value_grad_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_value_grad_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 34\u001b[0m     value, grad \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value, grad\n",
      "File \u001b[0;32m/Volumes/code/envs/mlx/lib/python3.11/site-packages/mlx/nn/utils.py:28\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.inner_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_fn\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(params)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(x, y):\n\u001b[0;32m----> 2\u001b[0m   y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mbigram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y_hat))\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (y_hat \u001b[38;5;241m-\u001b[39m y)\u001b[38;5;241m.\u001b[39msquare()\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36mBigramModel.__call__\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ix):\n\u001b[0;32m---> 10\u001b[0m   logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m ix\n\u001b[1;32m     11\u001b[0m   counts \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m     12\u001b[0m   probs \u001b[38;5;241m=\u001b[39m counts \u001b[38;5;241m/\u001b[39m counts\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "lossNgrad(words[:2], words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigramModel(\n",
      "  (layers): Linear(input_dims=27, output_dims=27, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How ML frameworksk lower down to hardware?\n",
    "\n",
    "\n",
    "Pytorch: Eager eval, Tracks the graphs directly through graphs -> supporting multiple backends (metal perf framework)\n",
    "TF: Not sure\n",
    "S4TF: Autograd engine is built into the language. Mark functions as differentiable, func.backwards(),  -> LLVM\n",
    "JAX: Function, mark it as grad, grad(function),  --> XLA\n",
    "MLX: Similar to numpy,  --> (LLVM*)\n",
    "XLA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
